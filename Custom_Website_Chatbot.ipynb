{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1Dc2CqTXjU-W"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate transformers\n",
        "!pip -q install sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " bitsandbytes accelerate for GPU based machine"
      ],
      "metadata": {
        "id": "mdDPeR3d_Ya0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install unstructured"
      ],
      "metadata": {
        "id": "7IIQIUkY6rts"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for cloud based vector db , we need client\n",
        "\n",
        "mongodb-client\n",
        "\n",
        "huggingface-client"
      ],
      "metadata": {
        "id": "cSwjmMp1Ayhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client==3.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8k7tTkPAfzX",
        "outputId": "24a77630-7fe4-4a24-ae40-0f69f6d3b74a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client==3.1.0\n",
            "  Using cached pinecone_client-3.1.0-py3-none-any.whl (210 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==3.1.0) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==3.1.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==3.1.0) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client==3.1.0) (2.0.7)\n",
            "Installing collected packages: pinecone-client\n",
            "  Attempting uninstall: pinecone-client\n",
            "    Found existing installation: pinecone-client 3.2.2\n",
            "    Uninstalling pinecone-client-3.2.2:\n",
            "      Successfully uninstalled pinecone-client-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-pinecone 0.1.0 requires pinecone-client<4.0.0,>=3.2.2, but you have pinecone-client 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pinecone-client-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "import pinecone\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "from langchain import HuggingFacePipeline\n",
        "from huggingface_hub import notebook_login\n",
        "import torch"
      ],
      "metadata": {
        "id": "BpZNlT8c6rqX"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract data from URL"
      ],
      "metadata": {
        "id": "HEpN3094Cfnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URLs = [\n",
        "    \"https://ineuron.ai/\"\n",
        "]"
      ],
      "metadata": {
        "id": "7YwCtBW-6rk4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredURLLoader(urls = URLs)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "OZOlqcE8C66c"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hunknCPdDKRu",
        "outputId": "8b0aebdf-6752-4e7a-b575-734b60c379b4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: numpy\n",
            "Version: 1.25.2\n",
            "Summary: Fundamental package for array computing in Python\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: accelerate, albumentations, altair, arviz, astropy, autograd, bitsandbytes, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda12x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, langchain, langchain-community, langchain-pinecone, librosa, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, pandas-stubs, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, sentence-transformers, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, transformers, unstructured, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T33ETl75YCL8",
        "outputId": "726a4119-144f-4450-f54b-7f3c67e6be9a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Learning with iNeuron made \\xa0<>\\n\\nTake your career to the next level with industry ready programs,\\n\\nAn entire learning ecosystem at your fingertips to make learning fun.\\n\\nChoose from a range of tech programs and make your next big career switch.\\n\\nExplore Courses\\n\\n55%\\n\\nAverage Salary Hike\\n\\n400+\\n\\nDifferent Courses\\n\\n10000+\\n\\nCareer Transitions\\n\\n400+\\n\\nHiring Partners\\n\\nLIVE NOW\\n\\nSupport System\\n\\nOur support system is live again, this time it is bigger, better and faster.\\n\\nExperience a tech community like never seen before\\n\\nTake me there\\n\\nOur Courses\\n\\nView all\\n\\nView all\\n\\nSuccess Stories\\n\\nView all\\n\\nFresher\\n\\nAbhisekh Bhuyan\\n\\nMLOps engineer\\n\\nI got job as an MLOps engineer at synapsica at 13 LPA PPO because of \"End to End projects MLOps\" from iNeuron.\\n\\nFrom\\n\\nFresher\\n\\nTo\\n\\n79% Increment\\n\\nSubham Kanungo\\n\\nAssociate Data Scientist\\n\\nI just joined EY as data analyst. It would not be possible with the support of Krish sir and Sudhanshu sir.\\n\\nFrom\\n\\nTo\\n\\n100% Increment\\n\\nSayan Saha\\n\\nSoftware Engineer - Python\\n\\nI am very happy to share that I have joined an organization as a Software Engineer - Python (CTC 8LPA).\\n\\nFrom\\n\\nTo\\n\\nFresher\\n\\nSushant Sur\\n\\nSenior Analyst\\n\\nFinally after the continuous guidance and support from Sudhanshu and Krish Sir, I am able to start my career with Dell as Senior Analyst.\\n\\nFrom\\n\\nIntern\\n\\nTo\\n\\n55% Increment\\n\\nNeeraj Bafila\\n\\nData Scientist\\n\\nWith the help of Data Science course I am able to transition from Sys admin to Data Scientist and joining Infosys. Thanks for superb mentoring.\\n\\nFrom\\n\\nTo\\n\\nFresher\\n\\nVaibhav Joshi\\n\\nConsultant\\n\\nI want to thank you iNeuron, I got placed at KPMG Bangalore because of the FSDA course. Thanks once again.\\n\\nFrom\\n\\nIntern\\n\\nTo\\n\\nFresher\\n\\nAdityaraj Chaudhari\\n\\nML Engineer\\n\\nI am delighted to inform you that I have successfully joined Zycus Infotech as trainee ML Engineer.\\n\\nFrom\\n\\nFresher\\n\\nTo\\n\\n300% Increment\\n\\nDisha Balpande\\n\\nML Engineer\\n\\nThank You so much for wonerful course and videos, I got a job at Adidas with 300% Hike.\\n\\nFrom\\n\\nTo\\n\\n150% Increment\\n\\nShubham Bharadwaj\\n\\nFinance Analyst\\n\\nI am beyond elated to announce that I have joined Deloitte USI as Analyst- Finance. Excited to move ahead in my carrer with biggest of the Big 4.\\n\\nFrom\\n\\nTo\\n\\n60% Increment\\n\\nPraveen Iyer\\n\\nSenior Software Engineer\\n\\nI have got an opportunity for a semiconductor chip manufacturing company in Bengaluru as Senior Software Engineer.\\n\\nFrom\\n\\nTo\\n\\nView all\\n\\nExplore Our Ecosystem\\n\\nA one-stop destination for all your learning to placement needs\\n\\nNeuro Lab\\n\\nGet premium access to a state-of-the-art virtual lab with infinite computing so you won\\'t need additional investments in high-end PCs\\n\\nJob Portal\\n\\nNew-age jobs need new-age technology, Build resumes in minutes, Apply for exclusive jobs or hire fresh talent we have you covered.\\n\\nOne Neuron\\n\\nSpecialized bundled programs tailored to cater to your specific requirements. 500+ Tech courses bundled to make learning easy and affordable\\n\\nSupport System\\n\\nComplex doubt or joining a like minded community at your fingertips\\n\\nInternship Portal\\n\\nChoose from over 500+ live projects across various domains Build, collaborate and grow with peers.\\n\\nTODO\\n\\nCompleted\\n\\nIn Progress\\n\\nBacklog\\n\\nBecome an affiliate\\n\\nEarn while you learn\\n\\nHall of fame\\n\\nLearn from alumnus who cracked the code\\n\\nI want to express my gratitude to Krish Naik, Sudhanshu Kumar and Sunny Savita for their instrumental role in my data science journey.\\n\\nAbhinav Dwivedi\\n\\nData Scientist, Softsensor.ai\\n\\nThanks to the iNeuron team for teaching me the skillsets to get this fantastic job. it was an amazing journey of 8-9 months. Special thanks to Sudhanshu sir\\n\\nSaransh Sehrawat\\n\\nAssociate Consultant, EY\\n\\nA big thanks to the iNeuron team for helping us to enhance our technical knowledge to achieve everyone\\'s dream. My gratitude to all instructors for all you have.\\n\\nPayel Tarafder\\n\\nSystem Engineer, TCS\\n\\nIt was through Krish\\'s videos that I first learned about INEURON, and without hesitation, I joined the inaugural FULL STACK DATA ANALYTICS Course in June 2022.\\n\\nRupam Gupta\\n\\nBusiness Analyst, Keseya\\n\\nHackathon\\n\\nEmbark on an adventure of creativity, teamwork, and coding brilliance using our advanced Hackathon Portal!\\n\\nOur Alumni\\'s Are Placed At\\n\\n500+ Hiring Partners\\n\\nFooter\\n\\ncontact@ineuron.ai\\n\\n+91 8071176111\\n\\nFacebook\\n\\nInstagram\\n\\nYoutube\\n\\nTwitter\\n\\nLinkedin\\n\\nDiscord\\n\\nCompany\\n\\nAbout us\\n\\nContact us\\n\\nFAQs\\n\\nCertificate verification\\n\\nPrivacy policy\\n\\nTerms and conditions\\n\\nProducts\\n\\nOne Neuron\\n\\nSupport System\\n\\nNeuro Lab\\n\\nJob Portal\\n\\nInternship Portal\\n\\nBecome an affiliate\\n\\nHall of fame\\n\\nHackathon', metadata={'source': 'https://ineuron.ai/'})]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunkins\n"
      ],
      "metadata": {
        "id": "Kx4eO-AxZ07U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(separator='\\n',\n",
        "                                      chunk_size = 1000,\n",
        "                                      chunk_overlap = 200)"
      ],
      "metadata": {
        "id": "kpV-Zbu0ZhHe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "UJhsopDMa3jP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAAjGc68cbri",
        "outputId": "54261f45-4518-4d95-a1bd-056233fb984b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWj-y0CKcedF",
        "outputId": "8090bf8e-ef3e-49c0-e90b-7f6eedae721f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Learning with iNeuron made \\xa0<>\\nTake your career to the next level with industry ready programs,\\nAn entire learning ecosystem at your fingertips to make learning fun.\\nChoose from a range of tech programs and make your next big career switch.\\nExplore Courses\\n55%\\nAverage Salary Hike\\n400+\\nDifferent Courses\\n10000+\\nCareer Transitions\\n400+\\nHiring Partners\\nLIVE NOW\\nSupport System\\nOur support system is live again, this time it is bigger, better and faster.\\nExperience a tech community like never seen before\\nTake me there\\nOur Courses\\nView all\\nView all\\nSuccess Stories\\nView all\\nFresher\\nAbhisekh Bhuyan\\nMLOps engineer\\nI got job as an MLOps engineer at synapsica at 13 LPA PPO because of \"End to End projects MLOps\" from iNeuron.\\nFrom\\nFresher\\nTo\\n79% Increment\\nSubham Kanungo\\nAssociate Data Scientist\\nI just joined EY as data analyst. It would not be possible with the support of Krish sir and Sudhanshu sir.\\nFrom\\nTo\\n100% Increment\\nSayan Saha\\nSoftware Engineer - Python', metadata={'source': 'https://ineuron.ai/'})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Model\n",
        "\n",
        "for converting the chunks in vector embeddings"
      ],
      "metadata": {
        "id": "BiwCJO1Fc-EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "qjY9A_L3cjUh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"ineuron\")"
      ],
      "metadata": {
        "id": "Abw0YQiKhoe3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7_EYw6yh-WJ",
        "outputId": "9ecacae5-5353-441d-bd60-e46def7c899d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_result"
      ],
      "metadata": {
        "id": "AKXr-w2BiB0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5MfsDUkiD5r",
        "outputId": "f6c0dff0-2acd-4b97-b806-ebae7aa612a0"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "\n",
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'cb595d7e-ef59-4962-98fd-8eaa747bf10d')\n",
        "#PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'aped-4627-b74a')"
      ],
      "metadata": {
        "id": "YCFoktX8fFQF"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"cb595d7e-ef59-4962-98fd-8eaa747bf10d\")\n",
        "index_name = pc.Index(\"website-bot\")"
      ],
      "metadata": {
        "id": "zAcCnGA9QkSl"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqX1ch6ELlZ0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ],
      "metadata": {
        "id": "P1Jt5v1elyEK"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain-pinecone langchain-openai langchain"
      ],
      "metadata": {
        "id": "P92j41iOHqr9"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "docsearch = PineconeVectorStore.from_texts([t.page_content for t in text_chunks], embeddings, index_name = index_name, api_key=PINECONE_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "N055301th-Hg",
        "outputId": "3816cb71-84df-4b7a-aac6-7f2e8b6b679f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PineconeConfigurationError",
          "evalue": "You haven't specified an Api-Key.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPineconeConfigurationError\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-1890c5e3fa83>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_pinecone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPineconeVectorStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdocsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPineconeVectorStore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPINECONE_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_pinecone/vectorstores.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 )\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mpinecone_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pinecone_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mpinecone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpinecone_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_pinecone/vectorstores.py\u001b[0m in \u001b[0;36mget_pinecone_index\u001b[0;34m(cls, index_name, pool_threads, pinecone_api_key)\u001b[0m\n\u001b[1;32m    372\u001b[0m             Pinecone Index instance.\"\"\"\n\u001b[1;32m    373\u001b[0m         \u001b[0m_pinecone_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinecone_api_key\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PINECONE_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         client = PineconeClient(\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_pinecone_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"langchain\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/control/pinecone.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, host, config, additional_headers, pool_threads, index_api, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcommands\u001b[0m \u001b[0magainst\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0mplane\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mto\u001b[0m \u001b[0msee\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mreceived\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mabstractions\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtransformations\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mSDK\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthis\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPinecone\u001b[0m \u001b[0mclient\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprint\u001b[0m \u001b[0mout\u001b[0m \u001b[0man\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mcurl\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mrun\u001b[0m \u001b[0myourself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mshare\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPinecone\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mBe\u001b[0m \u001b[0mvery\u001b[0m \u001b[0mcareful\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthis\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mprint\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/config/pinecone_config.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(api_key, host, additional_headers, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Ignoring PINECONE_ADDITIONAL_HEADERS: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mConfigBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/config/config.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(api_key, host, openapi_config, additional_headers, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mssl_ca_certs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mssl_verify\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0madditional_headers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     ) -> Config:\n",
            "\u001b[0;31mPineconeConfigurationError\u001b[0m: You haven't specified an Api-Key."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O7L8Qrn3jXvH",
        "outputId": "011df354-6302-4e4a-e127-3cd7f7821ab8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cb595d7e-ef59-4962-98fd-8eaa747bf10d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create LLM Wrapper"
      ],
      "metadata": {
        "id": "Q-f_E8-Ia3qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook login()"
      ],
      "metadata": {
        "id": "ineTwu7Qav0T"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                          use_auth_token=True,)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             use_auth_token=True,\n",
        "                                              load_in_8bit=True,\n",
        "                                              #load_in_4bit=True\n",
        "                                             )"
      ],
      "metadata": {
        "id": "ko3AWLoBavxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = transformers.pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )"
      ],
      "metadata": {
        "id": "G-Vq6yFEavuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "MFKI3Ed-avmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Please provide a concise summary of the Book Harry Potter\")"
      ],
      "metadata": {
        "id": "NKfbOH6d42Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the Retrieval QA"
      ],
      "metadata": {
        "id": "XOS-5DeO47fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "KFhYyiTo43pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "48yN9z224__9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me the course price of Full Stack Data Science with Generative AI provide by ineuron\"\n"
      ],
      "metadata": {
        "id": "xhxH0jM14_8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa.run(query))"
      ],
      "metadata": {
        "id": "Ng7pGWsv5FcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}